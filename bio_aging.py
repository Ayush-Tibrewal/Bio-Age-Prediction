# -*- coding: utf-8 -*-
"""Bio-Aging

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dg-SusBMRGRZfvmlnS6sI-IHvzhAm057
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
df = pd.read_csv("/content/drive/MyDrive/cleaned_kdm_bioage_NHANES32.csv")
print(df.head().to_markdown(index=False, numalign='left', stralign='left'))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV, KFold
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LassoCV, Ridge
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, explained_variance_score
from xgboost import XGBRegressor

df = pd.read_csv("/content/drive/MyDrive/cleaned_kdm_bioage_NHANES32.csv")

drop_cols = ['sampleID', 'wave', 'edu', 'ucod_leading', 'status', 'eligstat', 'diabetes', 'hyperten']
df = df.drop(columns=[col for col in drop_cols if col in df.columns])

df = df.dropna(subset=['kdm0'])

X = df.drop(columns=['kdm0'])
y = df['kdm0']

X = X.select_dtypes(include='number')

pipeline = Pipeline([
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler()),
    ("lasso", LassoCV(cv=5, random_state=0))
])

pipeline.fit(X, y)

lasso = pipeline.named_steps["lasso"]
coefficients = pd.Series(lasso.coef_, index=X.columns)

selected_features = coefficients[coefficients != 0].sort_values(key=abs, ascending=False)

print("Top features selected (PDA-style via Lasso):")
print(selected_features.to_markdown())

plt.figure(figsize=(8, 6))
colors = ['#e74c3c' if c < 0 else '#2ecc71' for c in selected_features]

plt.barh(selected_features.index, selected_features, color=colors)
plt.xlabel('Coefficient Value')
plt.title('Lasso Selected Feature Coefficients')
plt.axvline(0, color='gray', linestyle='--', linewidth=1, alpha=0.7)
plt.grid(axis='x', linestyle='--', alpha=0.5)

for i, v in enumerate(selected_features):
    plt.text(v + 0.01 * np.sign(v), i, f"{v:.2f}", va='center', fontsize=9)

plt.tight_layout()
plt.show()

df['bio_age_gap'] = df['kdm0'] - df['age']

# 3. Define age groups for grouping
df['age_group'] = pd.cut(
    df['age'],
    bins=[0, 18, 30, 45, 60, 75, 90],
    labels=['<18','18–30','30–45','45–60','60–75','75+']
)


age_gap_by_group = df.groupby('age_group')['bio_age_gap'].mean().reindex(['<18','18–30','30–45','45–60','60–75','75+'])
plt.figure(figsize=(8,5))
age_gap_by_group.plot(kind='bar')
plt.axhline(0, color='red', linestyle='--')
plt.title('Average Biological Age Gap by Age Group')
plt.xlabel('Age Group')
plt.ylabel('Mean (KDM – Chronological Age)')
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()

counts_by_group = df['age_group'].value_counts().reindex(['<18','18–30','30–45','45–60','60–75','75+'])
plt.figure(figsize=(8,5))
counts_by_group.plot(kind='bar')
plt.title('Number of Participants by Age Group')
plt.xlabel('Age Group')
plt.ylabel('Count')
plt.xticks(rotation=0)
plt.tight_layout()
plt.show()

counts = df['bio_age_gap'].gt(0).value_counts().reindex([True, False])
labels = ['Aging Faster','Aging Slower/On‑Track']
explode = [0.1, 0]  # highlight “Aging Faster” slice

plt.figure(figsize=(6,6))
plt.pie(
    counts,
    labels=labels,
    autopct='%1.1f%%',
    explode=explode,
    startangle=90,
    wedgeprops={'edgecolor':'k'}
)
plt.title('Proportion of Participants Aging Faster vs Slower/On‑Track')
plt.tight_layout()
plt.show()

"""# Simple Random forest"""

df = pd.read_csv("/content/drive/MyDrive/cleaned_kdm_bioage_NHANES32.csv")

features = [
    'age', 'fev', 'pulse', 'phenoage0', 'height',
    'income_recode', 'poverty_ratio', 'hba1c', 'waist'
]

target = 'kdm0'

df = df[features + [target]].dropna(subset=[target])

X = df[features]
y = df[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', MinMaxScaler()),  # Normalization [0,1]
    ('model', RandomForestRegressor(n_estimators=100, random_state=42))
])

pipeline.fit(X_train, y_train)

y_pred = pipeline.predict(X_test)

r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print(f"✅ R² Score: {r2:.4f}")
print(f"✅ RMSE: {rmse:.4f} years")

results_df = pd.DataFrame({
    "Actual_BioAge (kdm0)": y_test.values,
    "Predicted_BioAge": y_pred
})
print(results_df.head(10).to_markdown(index=False))

"""**Xg Boost**"""

df = pd.read_csv("/content/drive/MyDrive/cleaned_kdm_bioage_NHANES32.csv")

features = [
    'age', 'fev', 'pulse', 'phenoage0', 'height',
    'income_recode', 'poverty_ratio', 'hba1c', 'waist'
]
target = 'kdm0'

df = df[features + [target]].dropna()

X = df[features]
y = df[target]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

xgb = XGBRegressor(objective='reg:squarederror', random_state=42, verbosity=0)

param_grid = {
    'n_estimators': [50],
    'max_depth': [3, 5],
    'learning_rate': [0.1, 0.01]
}

grid = GridSearchCV(
    estimator=xgb,
    param_grid=param_grid,
    cv=KFold(n_splits=3, shuffle=True, random_state=42),
    scoring='r2',
    n_jobs=-1,
    verbose=1
)

grid.fit(X_train, y_train)

y_pred = grid.predict(X_test)
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print(f"R² Score: {r2:.4f}")
print(f"RMSE: {rmse:.4f} years")

y_true = y_test
y_pred = grid.predict(X_test)

# 1. Actual vs Predicted
plt.figure(figsize=(8,6))
sns.scatterplot(x=y_true, y=y_pred, alpha=0.7)
plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')
plt.xlabel('Actual Biological Age (kdm0)')
plt.ylabel('Predicted Biological Age')
plt.title('Actual vs Predicted')
plt.grid(True)
plt.tight_layout()
plt.show()

"""STACKED **MODEL**"""

# Define features and target
features = [
    'age', 'fev', 'pulse', 'phenoage0', 'kdm_advance0', 'height',
    'income_recode', 'poverty_ratio', 'hba1c', 'waist'
]
target = 'kdm0'

df = df[features + [target]].dropna()

z_scores = np.abs(zscore(df))
df_cleaned = df[(z_scores < 3).all(axis=1)]

# Split the cleaned data
X = df_cleaned[features]
y = df_cleaned[target]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define base models
base_models = [
    ('xgb', XGBRegressor(objective='reg:squarederror', n_estimators=50, max_depth=3, learning_rate=0.1, random_state=42)),
    ('rf', RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42)),
    ('gb', GradientBoostingRegressor(n_estimators=50, max_depth=3, learning_rate=0.1, random_state=42))
]

# Final estimator
final_model = Ridge(alpha=1.0)

# Stacking Regressor
stacking_model = StackingRegressor(
    estimators=base_models,
    final_estimator=final_model,
    passthrough=True,
    n_jobs=-1
)

# Full pipeline
pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler()),
    ('stack', stacking_model)
])

pipeline.fit(X_train, y_train)

y_pred = pipeline.predict(X_test)
r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

r2, rmse

plt.figure(figsize=(8,6))
sns.scatterplot(x=y_test, y=y_pred, alpha=0.7, color='dodgerblue')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Actual Biological Age (kdm0)")
plt.ylabel("Predicted Biological Age")
plt.title("Actual vs Predicted Biological Age")
plt.grid(True)
plt.tight_layout()
plt.show()

r2 = r2_score(y_test, y_pred)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
mae = mean_absolute_error(y_test, y_pred)
mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100
expl_var = explained_variance_score(y_test, y_pred)

print(f"R² Score: {r2:.4f}")
print(f"RMSE: {rmse:.4f} years")
print(f"MAE: {mae:.4f} years")
print(f"MAPE: {mape:.2f}%")
print(f"Explained Variance: {expl_var:.4f}")

"""Additional **Eda**"""

labs = ['bmi','waist','glucose','hba1c','sbp','dbp','hdl','ldl','bio_age_gap']
for status in ['No','Yes']:
    sub = df[df.diabetes==status][labs]
    plt.figure(figsize=(6,5))
    sns.heatmap(sub.corr(), annot=True, fmt='.2f', center=0, cmap='coolwarm')
    plt.title(f'Corr Matrix ({status})')
    plt.show()

sns.histplot(df['bio_age_gap'], bins=30, kde=True)
plt.axvline(0, color='red', linestyle='--')
plt.title('Distribution of Biological Age Gap (Biological - Chronological)')
plt.xlabel('Biological Age Gap (Years)')
plt.show()

sns.histplot(df['age'], bins=20, kde=True)
plt.title('Age Distribution')
plt.xlabel('Age')
plt.ylabel('Count')
plt.show()

df['age_group'] = pd.cut(df['age'], bins=[0, 18, 30, 45, 60, 80],
                         labels=['<18', '18-30', '30-45', '45-60', '60+'])

sns.countplot(data=df, x='age_group', hue='health')
plt.title('Health Status by Age Group')
plt.show()